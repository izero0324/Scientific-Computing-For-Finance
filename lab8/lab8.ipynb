{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Session 8 - Coursework Assignment #2\n",
    "## Preliminaries\n",
    "In this coursework you will analyse stocks comprising the Standard and Poor's 100 index. The assignment has been structured into separate exercises given below.\n",
    "\n",
    "You will need to download a .csv-file containing daily adjusted closing prices for the components of the S&P 100 index. This data can be downloaded from the KEATS page.\n",
    "\n",
    "You can then read this file into a Pandas DataFrame using code similar to that below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libaries\n",
    "- import numpy for scientific computing \n",
    "- import pandas for transforming csv to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> First, I will check the current working path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/andrewyang/Desktop/workspace/Scientific-Computing-For-Finance/lab8\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "current_path = os.getcwd()\n",
    "print(current_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> And then download the S&P index csv \"sap100.csv\" and move it under the working path we got on the previous step.\n",
    "> We'll check if the file really exists in the folder before doing futher analystics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "csv_path = current_path + '/sap100.csv'     # set the absolute path of the csv file\n",
    "print(os.path.isfile(csv_path))             # Return true if the file exists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. read the csv file we downloaded and checked last step by the function `pd.read_csv`\n",
    "> 2. save the dataframe as `prices`\n",
    "> 3. take a look of the dataframe `prices` to check if the indexs and columns are right by using the function `head()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>VZ</th>\n",
       "      <th>WBA</th>\n",
       "      <th>WFC</th>\n",
       "      <th>WMT</th>\n",
       "      <th>XOM</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ADBE</th>\n",
       "      <th>AIG</th>\n",
       "      <th>...</th>\n",
       "      <th>TMUS</th>\n",
       "      <th>TSLA</th>\n",
       "      <th>TXN</th>\n",
       "      <th>UNH</th>\n",
       "      <th>UNP</th>\n",
       "      <th>UPS</th>\n",
       "      <th>USB</th>\n",
       "      <th>V</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ACN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-06-06 00:00:00</td>\n",
       "      <td>24.657499</td>\n",
       "      <td>50.709999</td>\n",
       "      <td>78.660004</td>\n",
       "      <td>50.490002</td>\n",
       "      <td>71.050003</td>\n",
       "      <td>89.339996</td>\n",
       "      <td>39.169998</td>\n",
       "      <td>99.120003</td>\n",
       "      <td>57.290001</td>\n",
       "      <td>...</td>\n",
       "      <td>43.070000</td>\n",
       "      <td>14.712000</td>\n",
       "      <td>61.290001</td>\n",
       "      <td>138.149994</td>\n",
       "      <td>86.849998</td>\n",
       "      <td>103.110001</td>\n",
       "      <td>42.880001</td>\n",
       "      <td>80.540001</td>\n",
       "      <td>62.820000</td>\n",
       "      <td>119.599998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-06-07 00:00:00</td>\n",
       "      <td>24.757500</td>\n",
       "      <td>51.750000</td>\n",
       "      <td>79.120003</td>\n",
       "      <td>50.270000</td>\n",
       "      <td>71.029999</td>\n",
       "      <td>90.709999</td>\n",
       "      <td>38.930000</td>\n",
       "      <td>98.519997</td>\n",
       "      <td>57.060001</td>\n",
       "      <td>...</td>\n",
       "      <td>43.740002</td>\n",
       "      <td>15.489333</td>\n",
       "      <td>61.560001</td>\n",
       "      <td>136.940002</td>\n",
       "      <td>87.570000</td>\n",
       "      <td>103.870003</td>\n",
       "      <td>42.660000</td>\n",
       "      <td>80.599998</td>\n",
       "      <td>63.099998</td>\n",
       "      <td>119.650002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-06-08 00:00:00</td>\n",
       "      <td>24.735001</td>\n",
       "      <td>51.520000</td>\n",
       "      <td>79.440002</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>71.279999</td>\n",
       "      <td>90.790001</td>\n",
       "      <td>38.910000</td>\n",
       "      <td>98.680000</td>\n",
       "      <td>56.919998</td>\n",
       "      <td>...</td>\n",
       "      <td>43.910000</td>\n",
       "      <td>15.701333</td>\n",
       "      <td>62.080002</td>\n",
       "      <td>140.399994</td>\n",
       "      <td>89.040001</td>\n",
       "      <td>104.690002</td>\n",
       "      <td>42.810001</td>\n",
       "      <td>81.650002</td>\n",
       "      <td>61.730000</td>\n",
       "      <td>119.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-06-09 00:00:00</td>\n",
       "      <td>24.912500</td>\n",
       "      <td>51.950001</td>\n",
       "      <td>79.010002</td>\n",
       "      <td>49.139999</td>\n",
       "      <td>71.089996</td>\n",
       "      <td>90.669998</td>\n",
       "      <td>38.869999</td>\n",
       "      <td>98.070000</td>\n",
       "      <td>56.099998</td>\n",
       "      <td>...</td>\n",
       "      <td>43.080002</td>\n",
       "      <td>15.290667</td>\n",
       "      <td>62.139999</td>\n",
       "      <td>140.679993</td>\n",
       "      <td>89.389999</td>\n",
       "      <td>104.970001</td>\n",
       "      <td>42.540001</td>\n",
       "      <td>81.260002</td>\n",
       "      <td>60.750000</td>\n",
       "      <td>119.440002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-06-10 00:00:00</td>\n",
       "      <td>24.707500</td>\n",
       "      <td>52.669998</td>\n",
       "      <td>82.470001</td>\n",
       "      <td>48.340000</td>\n",
       "      <td>71.139999</td>\n",
       "      <td>89.980003</td>\n",
       "      <td>38.400002</td>\n",
       "      <td>97.089996</td>\n",
       "      <td>54.990002</td>\n",
       "      <td>...</td>\n",
       "      <td>41.930000</td>\n",
       "      <td>14.586000</td>\n",
       "      <td>61.910000</td>\n",
       "      <td>139.240005</td>\n",
       "      <td>88.779999</td>\n",
       "      <td>104.519997</td>\n",
       "      <td>41.959999</td>\n",
       "      <td>80.180000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>118.269997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Date       AAPL         VZ        WBA        WFC        WMT  \\\n",
       "0  2016-06-06 00:00:00  24.657499  50.709999  78.660004  50.490002  71.050003   \n",
       "1  2016-06-07 00:00:00  24.757500  51.750000  79.120003  50.270000  71.029999   \n",
       "2  2016-06-08 00:00:00  24.735001  51.520000  79.440002  50.000000  71.279999   \n",
       "3  2016-06-09 00:00:00  24.912500  51.950001  79.010002  49.139999  71.089996   \n",
       "4  2016-06-10 00:00:00  24.707500  52.669998  82.470001  48.340000  71.139999   \n",
       "\n",
       "         XOM        ABT       ADBE        AIG  ...       TMUS       TSLA  \\\n",
       "0  89.339996  39.169998  99.120003  57.290001  ...  43.070000  14.712000   \n",
       "1  90.709999  38.930000  98.519997  57.060001  ...  43.740002  15.489333   \n",
       "2  90.790001  38.910000  98.680000  56.919998  ...  43.910000  15.701333   \n",
       "3  90.669998  38.869999  98.070000  56.099998  ...  43.080002  15.290667   \n",
       "4  89.980003  38.400002  97.089996  54.990002  ...  41.930000  14.586000   \n",
       "\n",
       "         TXN         UNH        UNP         UPS        USB          V  \\\n",
       "0  61.290001  138.149994  86.849998  103.110001  42.880001  80.540001   \n",
       "1  61.560001  136.940002  87.570000  103.870003  42.660000  80.599998   \n",
       "2  62.080002  140.399994  89.040001  104.690002  42.810001  81.650002   \n",
       "3  62.139999  140.679993  89.389999  104.970001  42.540001  81.260002   \n",
       "4  61.910000  139.240005  88.779999  104.519997  41.959999  80.180000   \n",
       "\n",
       "        ABBV         ACN  \n",
       "0  62.820000  119.599998  \n",
       "1  63.099998  119.650002  \n",
       "2  61.730000  119.320000  \n",
       "3  60.750000  119.440002  \n",
       "4  61.000000  118.269997  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices = pd.read_csv(csv_path)              # read the s&p 100 csv file and store it in a dataframe\n",
    "prices.head()                               # check the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. We can see the dataframe has 102 columns, which is the fist 2 column `index` and `Date` with 100 stocks.\n",
    "> 2. The Date type is \"YYYY-MM-DD HH:MM:SS\"\n",
    "> 3. The price of the stocks are float numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "Choose a single stock from the index, and compute the corresponding daily, monthly and annual log-returns. For each sampling frequency, test whether the returns are normally distributed. Include appropriate graphs in your final report and ensure that you clearly explain your analysis in your own words.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> My thoughts:\n",
    "> 1. Choose a stock, which I decided to choose here is `Nvidia Corp`. Because I know more about this company and maybe having some basic knowledge of the company benifits the analyse.\n",
    "> 2. The symbol for Nvidia Corp is `NVDA`\n",
    "> 3. Select the column `Date` with `NVDA` and save it as `nvda_price`\n",
    "> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.indexing._LocIndexer at 0x137f10c80>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nvda_price = prices[['Date', 'NVDA']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "Compute the Jarque-Bera test statistic and \n",
    "p\n",
    "-values for all stocks in the index over daily, monthly and annual frequencies. Summarise your results in a single graph which shows three side-by-side boxplots of the test statistic comparing: daily, monthly and annual return distributions. Comment on whether your results support the claim that stock returns exhibit aggregational Gaussianity (see, e.g., Cont 2001; reference below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "Download data for the S&P 100 index (symbol ^OEX), and repeat Exercise 1 with this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "Estimate the \n",
    "Î±\n",
    " and \n",
    "Î²\n",
    " of each stock according to the single-index model using ordinary least squares regression over monthly excess returns, storing your results in a DataFrame. Produce a single graph showing side-by-side boxplots summarising the distribution of the alpha and beta coefficients over all stocks in the index.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5\n",
    "Compute the covariance matrix of the components of the index using the monthly excess-returns. According to the single-index model (see Elton and Gruber 1997; reference below), the covariance of a given pair of stocks should be directly proportional to the product of the corresponding \n",
    "Î²\n",
    " values. Test this hypothesis, and summarise your results in a single graph. Provide a written explanation of your results, and a short critical discussion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
